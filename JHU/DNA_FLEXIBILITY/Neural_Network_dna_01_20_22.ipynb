{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Importing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPClassifier,MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D\n",
    "\n",
    "from numpy.random import randn\n",
    "from numpy.random import seed\n",
    "from scipy.stats import pearsonr\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "import joblib\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nucleotide to unit vector\n",
    "def one_hot(base):\n",
    "  return np.array({'a':[1,0,0,0], \n",
    "                   't':[0,1,0,0], \n",
    "                   'g':[0,0,1,0], \n",
    "                   'c':[0,0,0,1]}[base.lower()])\n",
    "\n",
    "# replace nucleotide for unit vector using one_hon()\n",
    "def Hot(seq): \n",
    "  seq_one_hot = np.zeros((len(seq)*4, )) # zero 200,1 matrix \n",
    "  for i in range(len(seq)): seq_one_hot[4*i : 4*i+4] = one_hot(seq[i])\n",
    "  return seq_one_hot\n",
    "\n",
    "# normalize data (-1 to +1)\n",
    "def NormalizeData(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "# print results function\n",
    "def print_results(results):\n",
    "    print('Best Params: {}\\n'.format(results.best_params_))\n",
    "    \n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means,stds, results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}'.format(round(mean,3),round(std*2,3),params))\n",
    "\n",
    "        \n",
    "def clean_data(d1):\n",
    "    # change column name\n",
    "    d2 = d1.rename(columns={d1.columns[0]:'index',d1.columns[1]:'seq100',d1.columns[2]:'c26',d1.columns[3]:'c29', d1.columns[4]:'c31',d1.columns[5]:'c0'}) \n",
    "\n",
    "\n",
    "    # remove overhanger\n",
    "    seq =[]\n",
    "    for i in range(len(d2['seq100'])):\n",
    "        seq.append(d2['seq100'][i][25:75])\n",
    "    d3 = pd.DataFrame(seq,columns=['seq50'])\n",
    "    d4 = pd.concat([d2,d3],axis=1)\n",
    "    df = d4.drop(['index','seq100'],axis=1)\n",
    "\n",
    "    #take a random sample of 10000\n",
    "    df = df.sample(n=len(df))\n",
    "    return  df\n",
    "\n",
    "def encode_dna_seq(df):\n",
    "    # extract column of sequence\n",
    "    SeqList = df['seq50'].tolist()\n",
    "\n",
    "    # extract c0 values\n",
    "    dy = np.around(df['c0'].values,3) \n",
    "\n",
    "    # encode dna sequence\n",
    "    d = [] \n",
    "    for i in range(len(SeqList)): \n",
    "        d.append(Hot(SeqList[i])) \n",
    "    d = np.array(d)\n",
    "    dx = pd.DataFrame(d)\n",
    "    input = dx.values\n",
    "    return input,dy\n",
    "\n",
    "def split_data_tvt(dx,dy):\n",
    "    x_train, x_test, y_train, y_test  = train_test_split(dx,dy,shuffle=True, test_size=0.40, random_state=1234)\n",
    "    x_val, x_test, y_val, y_test  = train_test_split(x_test,y_test,shuffle=True, test_size=0.50, random_state=1234)\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready\n"
     ]
    }
   ],
   "source": [
    "d = pd.read_csv('C:/Users/bciez/Documents/Basilio/jhu/ha-lab/dna_flexibility/thesis_01_18_2022/data/dataset1.txt',delimiter='\\t')\n",
    "print('ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c26</th>\n",
       "      <th>c29</th>\n",
       "      <th>c31</th>\n",
       "      <th>c0</th>\n",
       "      <th>Amplitude</th>\n",
       "      <th>Phase</th>\n",
       "      <th>seq50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15513</th>\n",
       "      <td>-0.135085</td>\n",
       "      <td>-0.199342</td>\n",
       "      <td>0.091263</td>\n",
       "      <td>-0.029406</td>\n",
       "      <td>-0.199800</td>\n",
       "      <td>0.557327</td>\n",
       "      <td>TTCATTCCCTGTGTTTCTCATGAGACCTGCCCCAGGTCAATTGCAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3283</th>\n",
       "      <td>0.006846</td>\n",
       "      <td>-0.822869</td>\n",
       "      <td>-1.135966</td>\n",
       "      <td>-0.451458</td>\n",
       "      <td>-0.500327</td>\n",
       "      <td>-1.158017</td>\n",
       "      <td>CAGGGGTGGGCATGAATGCCGCAGCAAAAGGCATATCGGAAGTTGC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3983</th>\n",
       "      <td>-0.904064</td>\n",
       "      <td>-0.568635</td>\n",
       "      <td>-0.244993</td>\n",
       "      <td>-0.630426</td>\n",
       "      <td>-0.274063</td>\n",
       "      <td>-4.768100</td>\n",
       "      <td>TTAGCATTGGCACGCCAGTTGGATGTAGACATTTTATTGTGGGGTG...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            c26       c29       c31        c0   Amplitude     Phase  \\\n",
       "15513 -0.135085 -0.199342  0.091263 -0.029406   -0.199800  0.557327   \n",
       "3283   0.006846 -0.822869 -1.135966 -0.451458   -0.500327 -1.158017   \n",
       "3983  -0.904064 -0.568635 -0.244993 -0.630426   -0.274063 -4.768100   \n",
       "\n",
       "                                                   seq50  \n",
       "15513  TTCATTCCCTGTGTTTCTCATGAGACCTGCCCCAGGTCAATTGCAT...  \n",
       "3283   CAGGGGTGGGCATGAATGCCGCAGCAAAAGGCATATCGGAAGTTGC...  \n",
       "3983   TTAGCATTGGCACGCCAGTTGGATGTAGACATTTTATTGTGGGGTG...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = clean_data(d)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E. Encoding DNA sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready\n"
     ]
    }
   ],
   "source": [
    "dx,dy = encode_dna_seq(df)\n",
    "print('ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F. Split data in training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_val, y_val, x_test, y_test = split_data_tvt(dx,dy)\n",
    "print('ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# G. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'activation': 'logistic', 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'max_iter': 5000}\n",
      "\n",
      "0.114 (+/-0.102) for {'activation': 'relu', 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'max_iter': 5000}\n",
      "0.082 (+/-0.082) for {'activation': 'relu', 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'max_iter': 5000}\n",
      "-0.613 (+/-0.323) for {'activation': 'relu', 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'max_iter': 5000}\n",
      "-0.578 (+/-0.086) for {'activation': 'relu', 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'max_iter': 5000}\n",
      "-0.508 (+/-0.101) for {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 5000}\n",
      "-0.544 (+/-0.132) for {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling', 'max_iter': 5000}\n",
      "0.127 (+/-0.085) for {'activation': 'tanh', 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'max_iter': 5000}\n",
      "0.155 (+/-0.035) for {'activation': 'tanh', 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'max_iter': 5000}\n",
      "-0.597 (+/-0.152) for {'activation': 'tanh', 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'max_iter': 5000}\n",
      "-0.585 (+/-0.115) for {'activation': 'tanh', 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'max_iter': 5000}\n",
      "-0.292 (+/-0.133) for {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 5000}\n",
      "-0.3 (+/-0.051) for {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling', 'max_iter': 5000}\n",
      "0.191 (+/-0.032) for {'activation': 'logistic', 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'max_iter': 5000}\n",
      "0.207 (+/-0.056) for {'activation': 'logistic', 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'max_iter': 5000}\n",
      "-0.339 (+/-0.102) for {'activation': 'logistic', 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'max_iter': 5000}\n",
      "-0.362 (+/-0.108) for {'activation': 'logistic', 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'max_iter': 5000}\n",
      "-0.074 (+/-0.465) for {'activation': 'logistic', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 5000}\n",
      "-0.161 (+/-0.44) for {'activation': 'logistic', 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling', 'max_iter': 5000}\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPRegressor(iter)\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': [(10,),(50,),(100,)],\n",
    "    'activation': ['relu','tanh','logistic'],\n",
    "    'learning_rate':['constant','invscaling'],\n",
    "    'max_iter':[5000]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(mlp, parameters, cv = 5)\n",
    "cv.fit(x_train, y_train)\n",
    "\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H. Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mlp_model.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(cv.best_estimator_,'mlp_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='logistic', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=(10,), learning_rate='invscaling',\n",
       "             learning_rate_init=0.001, max_fun=15000, max_iter=5000,\n",
       "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "             power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
